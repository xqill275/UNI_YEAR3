{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44845405"
   },
   "source": [
    "## Exercise 1: Part-of-Speech Tagging with NLTK\n",
    "\n",
    "**Task**: Identify the grammatical category (Part-of-Speech) for each word in a given sentence.\n",
    "**Library**: NLTK (Natural Language Toolkit) is widely used for linguistic annotation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f21cd744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercise 1: Part-of-Speech Tagging with NLTK ---\n",
      "Original text: 'The quick brown fox jumps over the lazy dog.'\n",
      "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
      "Word: The, POS Tag: DT\n",
      "Word: quick, POS Tag: JJ\n",
      "Word: brown, POS Tag: NN\n",
      "Word: fox, POS Tag: NN\n",
      "Word: jumps, POS Tag: VBZ\n",
      "Word: over, POS Tag: IN\n",
      "Word: the, POS Tag: DT\n",
      "Word: lazy, POS Tag: JJ\n",
      "Word: dog, POS Tag: NN\n",
      "Word: ., POS Tag: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng') # Required for POS tagging for English\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(\"\\n--- Exercise 1: Part-of-Speech Tagging with NLTK ---\")\n",
    "text5 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens5 = word_tokenize(text5)\n",
    "pos_tags = nltk.pos_tag(tokens5) # Perform POS tagging on the tokens\n",
    "print(f\"Original text: '{text5}'\")\n",
    "print(f\"Tokens: {tokens5}\")\n",
    "print(f\"POS Tags: {pos_tags}\")\n",
    "# identify the grammatical categories of each word in the sentence\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"Word: {word}, POS Tag: {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmfRjFFd2Sl2"
   },
   "source": [
    "The abbreviations like DT, JJ, NN, etc., are Part-of-Speech (POS) tags used by NLTK. They represent the grammatical category of each word. Here's a breakdown of the ones you've seen and some common ones:\n",
    "\n",
    "- DT: Determiner (e.g., \"The\", \"a\", \"an\")\n",
    "- JJ: Adjective (e.g., \"quick\", \"brown\", \"lazy\", \"new\", \"brilliant\", \"few\", \"slow\")\n",
    "- NN: Noun, singular or mass (e.g., \"fox\", \"dog\", \"movie\", \"acting\", \"storyline\", \"edge\", \"seat\", \"bit\")\n",
    "- VBZ: Verb, 3rd person singular present (e.g., \"jumps\", \"is\")\n",
    "- IN: Preposition or subordinating conjunction (e.g., \"over\", \"on\", \"of\", \"though\")\n",
    "- .: Punctuation mark, sentence closer (e.g., \".\", \"!\")\n",
    "- RB: Adverb (e.g., \"absolutely\", \"highly\")\n",
    "- VBD: Verb, past tense (e.g., \"was\", \"kept\", \"were\")\n",
    "- VBN: Verb, past participle (e.g., \"superb\" - often tagged as VBN when acting as an adjective derived from a verb)\n",
    "- PRP: Personal pronoun (e.g., \"me\", \"I\", \"it\")\n",
    "- PRP$: Possessive pronoun (e.g., \"my\")\n",
    "- VBP: Verb, non-3rd person singular present (e.g., \"recommend\")\n",
    "- CC: Coordinating conjunction (e.g., \"and\")\n",
    "- NNS: Noun, plural (e.g., \"scenes\")\n",
    "\n",
    "These tags help in understanding the grammatical structure of sentences, which is foundational for many advanced NLP tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51a80379"
   },
   "source": [
    "## Exercise 2: Dependency Parsing with SpaCy\n",
    "\n",
    "**Task**: Analyze the grammatical structure of a sentence by identifying the head word for each word and the type of dependency relation between them.\n",
    "**Library**: SpaCy provides efficient and accurate dependency parsing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "28c65f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercise 2: Dependency Parsing with SpaCy ---\n",
      "Original text: 'Apple is looking at buying U.K. startup for $1 billion.'\n",
      "Dependency Parse:\n",
      "  Apple      PROPN      nsubj           looking   \n",
      "  is         AUX        aux             looking   \n",
      "  looking    VERB       ROOT            looking   \n",
      "  at         ADP        prep            looking   \n",
      "  buying     VERB       pcomp           at        \n",
      "  U.K.       PROPN      nsubj           startup   \n",
      "  startup    VERB       ccomp           buying    \n",
      "  for        ADP        prep            startup   \n",
      "  $          SYM        quantmod        billion   \n",
      "  1          NUM        compound        billion   \n",
      "  billion    NUM        pobj            for       \n",
      "  .          PUNCT      punct           looking   \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(\"\\n--- Exercise 2: Dependency Parsing with SpaCy ---\")\n",
    "# Load SpaCy model - ensure 'en_core_web_sm' is downloaded\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading en_core_web_sm model for SpaCy...\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text7 = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "doc = nlp(text7) # Process the text with the loaded SpaCy model\n",
    "\n",
    "print(f\"Original text: '{text7}'\")\n",
    "print(\"Dependency Parse:\")\n",
    "for token in doc:\n",
    "    # Print the token, its part-of-speech, its head word, and the dependency relation\n",
    "    print(f\"  {token.text:<10} {token.pos_:<10} {token.dep_:<15} {token.head.text:<10}\")\n",
    "\n",
    "# You can also visualize the dependency tree\n",
    "# For visualization, you might need to install 'displacy'\n",
    "# import displacy\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True, options={'compact': True, 'distance': 90})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ad2b44a"
   },
   "source": [
    "## Exercise 3: Text Classification with scikit-learn\n",
    "\n",
    "**Task**: Categorize text into predefined classes (e.g., positive/negative sentiment).\n",
    "**Library**: `scikit-learn` is a powerful and widely used machine learning library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d4888a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exercise 3: Text Classification with scikit-learn ---\n",
      "Original text for prediction: '['This movie is fantastic and I love it!', 'What a terrible film, absolutely dreadful.']'\n",
      "Actual labels: ['positive', 'negative']\n",
      "Predicted labels: ['negative' 'neutral']\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       1.0\n",
      "     neutral       0.00      0.00      0.00       0.0\n",
      "    positive       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "\n",
      "New sentence: 'I really enjoyed this production, very entertaining!'\n",
      "Predicted sentiment: negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # Often useful for text preprocessing in classification\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- Exercise 3: Text Classification with scikit-learn ---\")\n",
    "\n",
    "# Sample Dataset (simple movie review sentiments)\n",
    "texts = [\n",
    "    \"This movie is fantastic and I love it!\",\n",
    "    \"What a terrible film, absolutely dreadful.\",\n",
    "    \"The acting was good, but the plot was boring.\",\n",
    "    \"A truly amazing experience, highly recommended.\",\n",
    "    \"I hated every minute of this movie, so bad.\",\n",
    "    \"It was an okay film, nothing special.\"\n",
    "]\n",
    "labels = ['positive', 'negative', 'neutral', 'positive', 'negative', 'neutral'] # Corresponding labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline: Vectorizer -> Classifier\n",
    "# CountVectorizer converts text into a matrix of token counts\n",
    "# MultinomialNB (Naive Bayes) is a simple, yet effective classifier for text\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Train the classifier\n",
    "text_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "print(f\"Original text for prediction: '{X_test}'\")\n",
    "print(f\"Actual labels: {y_test}\")\n",
    "print(f\"Predicted labels: {predicted}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted, zero_division=0)) # Print classification metrics\n",
    "\n",
    "# Predict on a new unseen sentence\n",
    "new_sentence = \"I really enjoyed this production, very entertaining!\"\n",
    "predicted_sentiment = text_clf.predict([new_sentence])\n",
    "print(f\"\\nNew sentence: '{new_sentence}'\")\n",
    "print(f\"Predicted sentiment: {predicted_sentiment[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1fafd9a"
   },
   "source": [
    "## Challenge: Integrated NLP Pipeline\n",
    "\n",
    "**Task**: Take a new paragraph of text, perform several NLP steps on it, and then classify its sentiment. This exercise integrates concepts from Part-of-Speech Tagging, Dependency Parsing, and Text Classification.\n",
    "\n",
    "**Steps:**\n",
    "1.  **Choose a new paragraph of text.**\n",
    "2.  **Perform Tokenization and Part-of-Speech Tagging** using NLTK (similar to Exercise 1).\n",
    "3.  **Perform Dependency Parsing** using SpaCy to analyze the grammatical structure (similar to Exercise 2).\n",
    "4.  **Classify the sentiment** of the paragraph using the pre-trained `text_clf` model from Exercise 3. You might need to consider how to apply a sentence-level classifier to a paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 'The quick brown fox jumps over the lazy dog.'\n",
      "Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "POS Tags: [('Films', 'NNS'), ('are', 'VBP'), ('produced', 'VBN'), ('by', 'IN'), ('recording', 'VBG'), ('actual', 'JJ'), ('people', 'NNS'), ('and', 'CC'), ('objects', 'NNS'), ('with', 'IN'), ('cameras', 'NNS'), ('or', 'CC'), ('by', 'IN'), ('creating', 'VBG'), ('them', 'PRP'), ('using', 'VBG'), ('animation', 'NN'), ('techniques', 'NNS'), ('and', 'CC'), ('special', 'JJ'), ('effects', 'NNS'), ('.', '.'), ('They', 'PRP'), ('comprise', 'VBP'), ('a', 'DT'), ('series', 'NN'), ('of', 'IN'), ('individual', 'JJ'), ('frames', 'NNS'), (',', ','), ('but', 'CC'), ('when', 'WRB'), ('these', 'DT'), ('images', 'NNS'), ('are', 'VBP'), ('shown', 'VBN'), ('rapidly', 'RB'), ('in', 'IN'), ('succession', 'NN'), (',', ','), ('the', 'DT'), ('illusion', 'NN'), ('of', 'IN'), ('motion', 'NN'), ('is', 'VBZ'), ('given', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('viewer', 'NN'), ('.', '.'), ('Flickering', 'VBG'), ('between', 'IN'), ('frames', 'NNS'), ('is', 'VBZ'), ('not', 'RB'), ('seen', 'VBN'), ('due', 'JJ'), ('to', 'TO'), ('an', 'DT'), ('effect', 'NN'), ('known', 'VBN'), ('as', 'IN'), ('persistence', 'NN'), ('of', 'IN'), ('vision', 'NN'), (',', ','), ('whereby', 'WRB'), ('the', 'DT'), ('eye', 'NN'), ('retains', 'VBZ'), ('a', 'DT'), ('visual', 'JJ'), ('image', 'NN'), ('for', 'IN'), ('a', 'DT'), ('fraction', 'NN'), ('of', 'IN'), ('a', 'DT'), ('second', 'JJ'), ('after', 'IN'), ('the', 'DT'), ('source', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('removed', 'VBN'), ('.', '.'), ('Also', 'RB'), ('of', 'IN'), ('relevance', 'NN'), ('is', 'VBZ'), ('what', 'WP'), ('causes', 'VBZ'), ('the', 'DT'), ('perception', 'NN'), ('of', 'IN'), ('motion', 'NN'), (';', ':'), ('a', 'DT'), ('psychological', 'JJ'), ('effect', 'NN'), ('identified', 'VBN'), ('as', 'IN'), ('beta', 'JJ'), ('movement', 'NN'), ('.', '.')]\n",
      "Dependency Parse:\n",
      "  Films      NOUN       nsubjpass       produced  \n",
      "  are        AUX        auxpass         produced  \n",
      "  produced   VERB       ROOT            produced  \n",
      "  by         ADP        agent           produced  \n",
      "  recording  VERB       pcomp           by        \n",
      "  actual     ADJ        amod            people    \n",
      "  people     NOUN       dobj            recording \n",
      "  and        CCONJ      cc              recording \n",
      "  objects    VERB       conj            recording \n",
      "  with       ADP        prep            objects   \n",
      "  cameras    NOUN       pobj            with      \n",
      "  or         CCONJ      cc              by        \n",
      "  by         ADP        conj            by        \n",
      "  creating   VERB       pcomp           by        \n",
      "  them       PRON       dobj            creating  \n",
      "  using      VERB       advcl           creating  \n",
      "  animation  NOUN       compound        techniques\n",
      "  techniques NOUN       dobj            using     \n",
      "  and        CCONJ      cc              techniques\n",
      "  special    ADJ        amod            effects   \n",
      "  effects    NOUN       conj            techniques\n",
      "  .          PUNCT      punct           produced  \n",
      "  They       PRON       nsubj           comprise  \n",
      "  comprise   VERB       ROOT            comprise  \n",
      "  a          DET        det             series    \n",
      "  series     NOUN       dobj            comprise  \n",
      "  of         ADP        prep            series    \n",
      "  individual ADJ        amod            frames    \n",
      "  frames     NOUN       pobj            of        \n",
      "  ,          PUNCT      punct           comprise  \n",
      "  but        CCONJ      cc              comprise  \n",
      "  when       SCONJ      advmod          shown     \n",
      "  these      DET        det             images    \n",
      "  images     NOUN       nsubjpass       shown     \n",
      "  are        AUX        auxpass         shown     \n",
      "  shown      VERB       advcl           given     \n",
      "  rapidly    ADV        advmod          shown     \n",
      "  in         ADP        prep            shown     \n",
      "  succession NOUN       pobj            in        \n",
      "  ,          PUNCT      punct           given     \n",
      "  the        DET        det             illusion  \n",
      "  illusion   NOUN       nsubjpass       given     \n",
      "  of         ADP        prep            illusion  \n",
      "  motion     NOUN       pobj            of        \n",
      "  is         AUX        auxpass         given     \n",
      "  given      VERB       conj            comprise  \n",
      "  to         ADP        dative          given     \n",
      "  the        DET        det             viewer    \n",
      "  viewer     NOUN       pobj            to        \n",
      "  .          PUNCT      punct           comprise  \n",
      "  Flickering VERB       nsubjpass       seen      \n",
      "  between    ADP        prep            Flickering\n",
      "  frames     NOUN       pobj            between   \n",
      "  is         AUX        auxpass         seen      \n",
      "  not        PART       neg             seen      \n",
      "  seen       VERB       ROOT            seen      \n",
      "  due        ADP        prep            seen      \n",
      "  to         ADP        pcomp           due       \n",
      "  an         DET        det             effect    \n",
      "  effect     NOUN       pobj            to        \n",
      "  known      VERB       acl             effect    \n",
      "  as         ADP        prep            known     \n",
      "  persistence NOUN       pobj            as        \n",
      "  of         ADP        prep            persistence\n",
      "  vision     NOUN       pobj            of        \n",
      "  ,          PUNCT      punct           persistence\n",
      "  whereby    SCONJ      advmod          retains   \n",
      "  the        DET        det             eye       \n",
      "  eye        NOUN       nsubj           retains   \n",
      "  retains    VERB       relcl           effect    \n",
      "  a          DET        det             image     \n",
      "  visual     ADJ        amod            image     \n",
      "  image      NOUN       dobj            retains   \n",
      "  for        ADP        prep            retains   \n",
      "  a          DET        det             fraction  \n",
      "  fraction   NOUN       pobj            for       \n",
      "  of         ADP        prep            fraction  \n",
      "  a          DET        det             second    \n",
      "  second     ADJ        pobj            of        \n",
      "  after      SCONJ      mark            removed   \n",
      "  the        DET        det             source    \n",
      "  source     NOUN       nsubjpass       removed   \n",
      "  has        AUX        aux             removed   \n",
      "  been       AUX        auxpass         removed   \n",
      "  removed    VERB       advcl           retains   \n",
      "  .          PUNCT      punct           seen      \n",
      "  Also       ADV        advmod          is        \n",
      "  of         ADP        prep            is        \n",
      "  relevance  NOUN       pobj            of        \n",
      "  is         AUX        ROOT            is        \n",
      "  what       PRON       nsubj           causes    \n",
      "  causes     VERB       ccomp           is        \n",
      "  the        DET        det             perception\n",
      "  perception NOUN       dobj            causes    \n",
      "  of         ADP        prep            perception\n",
      "  motion     NOUN       pobj            of        \n",
      "  ;          PUNCT      punct           effect    \n",
      "  a          DET        det             effect    \n",
      "  psychological ADJ        amod            effect    \n",
      "  effect     NOUN       appos           what      \n",
      "  identified VERB       acl             effect    \n",
      "  as         ADP        prep            identified\n",
      "  beta       NOUN       compound        movement  \n",
      "  movement   NOUN       pobj            as        \n",
      "  .          PUNCT      punct           is        \n",
      "\n",
      "Sentiment Analysis:\n",
      "Polarity: 0.03316326530612245, Subjectivity: 0.2209183673469388\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nltk.download('punkt') # Required for tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\") # Load SpaCy model\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "paragraph = \"Films are produced by recording actual people and objects with cameras or by creating them using animation techniques and special effects. They comprise a series of individual frames, but when these images are shown rapidly in succession, the illusion of motion is given to the viewer. Flickering between frames is not seen due to an effect known as persistence of vision, whereby the eye retains a visual image for a fraction of a second after the source has been removed. Also of relevance is what causes the perception of motion; a psychological effect identified as beta movement. \"\n",
    "\n",
    "# tokenisation and part-of-speech tagging\n",
    "tokens = nltk.word_tokenize(paragraph)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(f\"Original text: '{text5}'\")\n",
    "print(f\"Tokens: {tokens5}\")\n",
    "print(f\"POS Tags: {pos_tags}\")\n",
    "\n",
    "# dependency parsing\n",
    "doc = nlp(paragraph)\n",
    "print(\"Dependency Parse:\")\n",
    "for token in doc:\n",
    "    print(f\"  {token.text:<10} {token.pos_:<10} {token.dep_:<15} {token.head.text:<10}\")\n",
    "    \n",
    "\n",
    "\n",
    "# sentiment of the paragraph\n",
    "blob = TextBlob(paragraph)\n",
    "sentiment = blob.sentiment\n",
    "print(\"\\nSentiment Analysis:\")\n",
    "print(f\"Polarity: {sentiment.polarity}, Subjectivity: {sentiment.subjectivity}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6ZJiSsLYFqEggyHFG6ZF1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
