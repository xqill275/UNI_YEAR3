{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmRCOLxfDThsaEkvHq5NVq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FH3GMNUyHHP7"},"outputs":[],"source":["# This notebook demonstrates fundamental Natural Language Processing (NLP) tasks using popular Python libraries.\n","# Each exercise focuses on a specific NLP technique:\n","# 1.  **Tokenization** with NLTK\n","# 2.  **Named Entity Recognition (NER)** with SpaCy\n","# 3.  **Sentiment Analysis** with TextBlob\n","# 4.  **Text Summarization** with Sumy\n"]},{"cell_type":"markdown","metadata":{"id":"51e8144d"},"source":["### Explanation of NLP Concepts:\n","\n","1.  **Tokenization** with NLTK: The process of breaking down a text into smaller units called tokens, which can be words, subwords, or characters. NLTK provides tools like `word_tokenize` for this task.\n","\n","2.  **Named Entity Recognition (NER)** with SpaCy: A technique to identify and classify named entities in text into predefined categories such as person names, organizations, locations, expressions of times, quantities, monetary values, etc. SpaCy is a library widely used for this purpose.\n","\n","3.  **Sentiment Analysis** with TextBlob: The computational study of opinions, sentiments, and emotions expressed in text. It determines the emotional tone behind a piece of text, often classifying it as positive, negative, or neutral. TextBlob offers a simple API for sentiment analysis.\n","\n","4.  **Text Summarization** with Sumy: The process of condensing a longer text into a shorter, coherent, and fluent version while retaining the most important information and overall meaning of the original text. Sumy is a Python library that provides various summarization algorithms, like LSA."]},{"cell_type":"markdown","metadata":{"id":"2ce59bdc"},"source":["## Import Libraries and Download Resources"]},{"cell_type":"code","metadata":{"id":"dbbd2a6f"},"source":["import nltk\n","nltk.download('punkt') # Required for NLTK's word tokenizer\n","nltk.download('punkt_tab') # Required for some NLTK tokenizer functionalities (e.g., used by Sumy)\n","from nltk.tokenize import word_tokenize\n","\n","import spacy\n","\n","from textblob import TextBlob"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27805d67"},"source":["## Install `sumy` library"]},{"cell_type":"code","metadata":{"id":"d1bb5134"},"source":["# Install sumy if not already installed\n","!pip install sumy\n","\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","nltk.download('stopwords') # Sumy often uses NLTK stopwords for summarization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6a4fd0b"},"source":["## Exercise 1: Tokenization with NLTK\n","\n","**Task**: Break down a given text into individual words or tokens.\n","**Library**: NLTK (Natural Language Toolkit) is a powerful library for working with human language data."]},{"cell_type":"code","metadata":{"id":"4ffadef4"},"source":["print(\"\\n--- Exercise 1: Tokenization with NLTK ---\")\n","text1 = \"Natural Language Processing enables computers to understand human language.\"\n","tokens = word_tokenize(text1) # Uses NLTK's word_tokenize function to split the text\n","print(f\"Original text: '{text1}'\")\n","print(f\"Tokens: {tokens}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d81172bb"},"source":["### Challenge 1: Tokenization\n","\n","**Task**: Experiment with different NLTK tokenizers. For example, try `wordpunct_tokenize` or `TreebankWordTokenizer` (after importing if necessary) and observe the differences in tokenization for the given text or a new sentence of your choice. Pay attention to how punctuation is handled.\n","\n","**Hint**: You might need to import `nltk.tokenize.wordpunct_tokenize` or `nltk.tokenize.TreebankWordTokenizer`."]},{"cell_type":"markdown","metadata":{"id":"ba596589"},"source":["## Exercise 2: Named Entity Recognition with SpaCy\n","\n","**Task**: Identify and classify named entities (like persons, organizations, locations) in text.\n","**Library**: SpaCy is an industrial-strength natural language processing library in Python."]},{"cell_type":"code","metadata":{"id":"0a2fa08f"},"source":["print(\"\\n--- Exercise 2: Named Entity Recognition with SpaCy ---\")\n","# Load SpaCy model - ensure 'en_core_web_sm' is downloaded (you might need !python -m spacy download en_core_web_sm)\n","try:\n","    nlp = spacy.load(\"en_core_web_sm\") # Loads a small English model for processing\n","except OSError:\n","    print(\"Downloading en_core_web_sm model for SpaCy...\")\n","    from spacy.cli import download\n","    download(\"en_core_web_sm\") # If model is not found, download it automatically\n","    nlp = spacy.load(\"en_core_web_sm\")\n","\n","text2 = \"Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\"\n","doc = nlp(text2) # Process the text with the loaded SpaCy model\n","print(f\"Original text: '{text2}'\")\n","print(\"Named Entities:\")\n","for ent in doc.ents: # Iterate through the detected entities\n","    print(f\"  {ent.text:<20} {ent.label_}\") # Print the entity text and its label (e.g., PERSON, ORG)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4f7c749"},"source":["### Challenge 2: Named Entity Recognition\n","\n","**Task**: Apply NER to a new sentence that contains different types of entities (e.g., dates, monetary values, products). Analyze the output and see if SpaCy correctly identifies and labels them. What happens if you use a sentence with less common entities?\n","\n","**Example Sentence**: \"Apple released the iPhone 15 in September 2023 for $799. The event took place in Cupertino, California.\""]},{"cell_type":"markdown","metadata":{"id":"de626309"},"source":["## Exercise 3: Sentiment Analysis with TextBlob\n","\n","**Task**: Determine the emotional tone behind a piece of text, usually categorizing it as positive, negative, or neutral.\n","**Library**: TextBlob is a simple Python library for processing textual data. It provides a simple API for common NLP tasks."]},{"cell_type":"code","metadata":{"id":"5e5bd906"},"source":["print(\"\\n--- Exercise 3: Sentiment Analysis with TextBlob ---\")\n","text3 = \"I am extremely happy with the service provided.\"\n","blob = TextBlob(text3) # Create a TextBlob object from the text\n","sentiment = blob.sentiment # Access the sentiment property, which returns polarity and subjectivity\n","print(f\"Original text: '{text3}'\")\n","print(f\"Sentiment: {sentiment}\") # Polarity ranges from -1 (negative) to 1 (positive), Subjectivity from 0 (objective) to 1 (subjective)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6117e393"},"source":["### Challenge 3: Sentiment Analysis\n","\n","**Task**: Choose a short paragraph from a product review or a news article. Perform sentiment analysis using TextBlob. Analyze the `polarity` and `subjectivity` scores. How well does it align with your own understanding of the text's sentiment? Try sentences with sarcasm or nuanced language and observe the results."]},{"cell_type":"markdown","metadata":{"id":"2f43ac1e"},"source":["## Exercise 4: Text Summarization with Sumy\n","\n","**Task**: Condense a longer text into a shorter version while retaining the most important information.\n","**Library**: Sumy is a Python library for automatic text summarization of text documents."]},{"cell_type":"code","metadata":{"id":"ed137d14"},"source":["print(\"\\n--- Exercise 4: Text Summarization with Sumy ---\")\n","text4 = \"Natural Language Processing (NLP) is a fascinating field at the intersection of computer science, artificial intelligence, and linguistics. It enables machines to understand, interpret, and generate human language, opening up a world of possibilities for applications ranging from chatbots and translation services to sentiment analysis and beyond. This field involves various techniques, including machine learning, deep learning, and rule-based methods, to process and analyze large amounts of text data. The goal of NLP is to bridge the communication gap between humans and computers, allowing for more natural and intuitive interactions. Its applications are constantly expanding, making it a critical area of research and development in today's technologically driven world.\"\n","parser = PlaintextParser.from_string(text4, Tokenizer(\"english\")) # Parse the text using Sumy's PlaintextParser and English tokenizer\n","summarizer = LsaSummarizer() # Initialize an LSA (Latent Semantic Analysis) summarizer\n","summary = summarizer(parser.document, 2)  # Summarize the document into 2 sentences\n","print(f\"Original text (first 100 chars): '{text4[:100]}...' \")\n","print(\"Summary (2 sentences):\")\n","for sentence in summary:\n","    print(f\"  - {sentence}\") # Print each sentence of the generated summary"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3bf1b305"},"source":["### Challenge 4: Text Summarization\n","\n","**Task**: Take a longer article or a portion of text (e.g., from Wikipedia) and apply Sumy's LSA summarizer. Experiment with different numbers of sentences for the summary (e.g., 3, 5). Compare the generated summaries to see which one best captures the essence of the original text while remaining concise. You can also explore other summarization algorithms available in Sumy if you're feeling adventurous (e.g., `LexRankSummarizer`)."]}]}